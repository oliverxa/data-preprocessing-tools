{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm \n",
    "import sklearn.cluster as cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(x, centroids):\n",
    "    dists = []\n",
    "    for centroid in centroids:\n",
    "        c_w, c_h = centroid\n",
    "        w, h = x\n",
    "        if c_w >= w and c_h >= h:\n",
    "            dist = w * h / (c_w * c_h)\n",
    "        elif c_w >= w and c_h <= h:\n",
    "            dist = w * c_h / (w * h + (c_w - w) * c_h)\n",
    "        elif c_w <= w and c_h >= h:\n",
    "            dist = c_w * h / (w * h + c_w * (c_h - h))\n",
    "        else:  # means both w,h are bigger than c_w and c_h respectively\n",
    "            dist = (c_w * c_h) / (w * h)\n",
    "        dists.append(dist)\n",
    "    return np.array(dists)\n",
    "\n",
    "\n",
    "def avg_iou(x, centroids):\n",
    "    n, d = x.shape\n",
    "    sums = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        # note IOU() will return array which contains IoU for each centroid and X[i]\n",
    "        # slightly ineffective, but I am too lazy\n",
    "        sums += max(iou(x[i], centroids))\n",
    "    return sums / n\n",
    "\n",
    "\n",
    "def write_anchors_to_file(centroids, distance, anchor_file):\n",
    "    anchors = centroids * 416 / 32      # I do not know whi it is 416/32\n",
    "    anchors = [str(i) for i in anchors.ravel()]\n",
    "    print(\n",
    "        \"\\n\",\n",
    "        \"Cluster Result:\\n\",\n",
    "        \"Clusters:\", len(centroids), \"\\n\",\n",
    "        \"Average IoU:\", distance, \"\\n\",\n",
    "        \"Anchors:\\n\",\n",
    "        \", \".join(anchors)\n",
    "    )\n",
    "\n",
    "    with open(anchor_file, 'w') as f:\n",
    "        f.write(\", \".join(anchors))\n",
    "        f.write('\\n%f\\n' % distance)\n",
    "\n",
    "\n",
    "def k_means(x, n_clusters, eps):\n",
    "    init_index = [random.randrange(x.shape[0]) for _ in range(n_clusters)]\n",
    "    centroids = x[init_index]\n",
    "\n",
    "    d = old_d = []\n",
    "    iterations = 0\n",
    "    diff = 1e10\n",
    "    c, dim = centroids.shape\n",
    "\n",
    "    while True:\n",
    "        iterations += 1\n",
    "        d = np.array([1 - iou(i, centroids) for i in x])\n",
    "        if len(old_d) > 0:\n",
    "            diff = np.sum(np.abs(d - old_d))\n",
    "\n",
    "        print('diff = %f' % diff)\n",
    "\n",
    "        if diff < eps or iterations > 1000:\n",
    "            print(\"Number of iterations took = %d\" % iterations)\n",
    "            print(\"Centroids = \", centroids)\n",
    "            return centroids\n",
    "\n",
    "        # assign samples to centroids\n",
    "        belonging_centroids = np.argmin(d, axis=1)\n",
    "\n",
    "        # calculate the new centroids\n",
    "        centroid_sums = np.zeros((c, dim), np.float)\n",
    "        for i in range(belonging_centroids.shape[0]):\n",
    "            centroid_sums[belonging_centroids[i]] += x[i]\n",
    "\n",
    "        for j in range(c):\n",
    "            centroids[j] = centroid_sums[j] / np.sum(belonging_centroids == j)\n",
    "\n",
    "        old_d = d.copy()\n",
    "\n",
    "\n",
    "def get_file_content(fnm):\n",
    "    with open(fnm) as f:\n",
    "        return [line.strip() for line in f]\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    print(\"Reading Data ...\")\n",
    "\n",
    "    file_list = []\n",
    "    for f in args.file_list:\n",
    "        file_list.extend(get_file_content(f))\n",
    "\n",
    "    data = []\n",
    "    for one_file in tqdm(file_list):\n",
    "        one_file = one_file.replace('images', 'labels') \\\n",
    "            .replace('JPEGImages', 'labels') \\\n",
    "            .replace('.png', '.txt') \\\n",
    "            .replace('.jpg', '.txt')\n",
    "        for line in get_file_content(one_file):\n",
    "            clazz, xx, yy, w, h = line.split()\n",
    "            data.append([float(w),float(h)]) \n",
    "\n",
    "    data = np.array(data)\n",
    "    if args.engine.startswith(\"sklearn\"):\n",
    "        if args.engine == \"sklearn\":\n",
    "            km = cluster.KMeans(n_clusters=args.num_clusters, tol=args.tol, verbose=True)\n",
    "        elif args.engine == \"sklearn-mini\":\n",
    "            km = cluster.MiniBatchKMeans(n_clusters=args.num_clusters, tol=args.tol, verbose=True)\n",
    "        km.fit(data)\n",
    "        result = km.cluster_centers_\n",
    "        # distance = km.inertia_ / data.shape[0]\n",
    "        distance = avg_iou(data, result)\n",
    "    else:\n",
    "        result = k_means(data, args.num_clusters, args.tol)\n",
    "        distance = avg_iou(data, result)\n",
    "\n",
    "    write_anchors_to_file(result, distance, args.output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--num_clusters NUM_CLUSTERS]\n",
      "                             [--output OUTPUT] [--tol TOL]\n",
      "                             [--engine {original,sklearn,sklearn-mini}]\n",
      "                             file_list [file_list ...]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if \"__main__\" == __name__:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('file_list', nargs='+', help='TrainList')\n",
    "    parser.add_argument('--num_clusters', '-n', default=5, type=int, help='Number of Clusters')\n",
    "    parser.add_argument('--output', '-o', default='../results/anchor.txt', type=str, help='Result Output File')\n",
    "    parser.add_argument('--tol', '-t', default=0.005, type=float, help='Tolerate')\n",
    "    parser.add_argument('--engine', '-m', default='sklearn', type=str,\n",
    "                        choices=['original', 'sklearn', 'sklearn-mini'], help='Method to use')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
